# Practice_L0

Приложение состоит из двух основных сервисов: Producer и Consumer, которые взаимодействуют с Kafka. Producer отправляет данные в Kafka, а Consumer читает данные из нее и обрабатывает их, сохраняя в базе данных PostgreSQL. Producer является скриптом записи данных заказа в топик кафки. При реализации consumer реализована слоеная архитектруа. Доступ к прочитанным заказам осуществляется через http интерфейс веб сервера на порту 9090.

## Требования

* Docker

* Go (Version go1.23.2)

* Posgresql 

* Kafka

## Запуск проекта

Для запуска проетка необходимо: 
1. Перейти в корневую директорию
2. Выполнить команду `docker-compose -f docker-compose.yml build`
3. Выполнить команду `docker-compose -f docker-compose.yml up --no-start`
4. Запустить контейнеры zoo и db и дождаться их полного запуска
5. Далее запустить контейнер broker и ждём его полного запуска
6. Далее запускаем контейнер init-kafka, который выполняет скрипт для создания топика
7. Запускаем consumer и producer для генерации и чтения данных.

По адресу localhost:9090 будет доступен веб-интерфейс для получения данных

## Использование
В приложении реализованы следующие методы: 

### Get Order
Получение заказа из базы данных (если такой существует).

Эндпоинт:
```
GET http://localhost:9090/api/getOrder?OrderUID=uuid
```
где uuid - uuid необходимого заказа.

При отсутствии query параметра данный метод также проверяет наличие значения OrderUID в JSON-body. 

В качестве ответа клиент получает все необходимые данные о заказе в json формате.

### Get Order using interface
Получение заказа через простейший интерфейс

Эндпоинт:
```
GET http://localhost:9090/
```

## Восстановление работы сервиса consumer
При старте сервиса происходит восстановление кэша последними записанными в базу заказами в соответствии с максимальным размером кэша. 


### CACHE
Кэш хранится в оперативной памяти. Оперативная память сервиса ограничена, поэтому внутри сервиса необходимо контролировать размер кэша. Из-за этого в процессе работы сервиса количество заказов в базе будет превышать максимальное количество заказов в кэше, и поэтому необходимо выбрать стратегию поддержания актуальности кэша. В условии ТЗ не прописан паттерн чтения данных, поэтому для вымещения ордеров из кэша была выбрана стратегия вымещения по времени создания (удалять наиболее старые). Максимальный размер кэша определяется в количестве заказов, это число хранится в конфиге сервиса.

При инициализации сервиса кэш заполняется последними вставленными в бд заказами. 

## Тестирование
Для проекта были написаны юнит-тесты, проверяющие основную логику сервиса consumer. Совместная работа сервисов проверялась вручную.

## Producer 

Скрипт для генерации заказов и отправки в топик "orders" в Kafka, используя библиотеку для работы с Kafka в Go. Для генерации случайных данных использована библиотека gofakeit. Данные отправляются в заданный интервал времени.

## Consumer 

Для получения данных из кафки создана группа слушателей "bank". Читаемые из канала данные записываются в базу данных, затем попадая в кэш. При запросе ордера ненайденные в кэше ищутся в базе данных. Реализован gracefull shutdown для корректного заверщения работы сервиса.

